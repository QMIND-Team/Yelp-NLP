{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Need go first import the libraries we're gonna need for this exercise, will start by importing scrapy \n",
    "\n",
    "import scrapy \n",
    "\n",
    "#We now define a class that will do our desired scraping for text using scrapy's built-in \"spiders\"\n",
    "#These spiders essentially are a template that provide different functionality from spider to spider \n",
    "#For our intents and purposes, will be using the vanilla scrapy.Spider flavour\n",
    "\n",
    "class QuoteSpider(scrapy.Spider):\n",
    "    \n",
    "    #Now we must assign a name to our particular spider that will be outlined by the class definition so we can call it when we want to use it\n",
    "    \n",
    "    name = \"quotes\"\n",
    "    \n",
    "    #Now must provide the urls to the websites we wish to scrape data from, could make this universal by having a variable hold url data, but for our example there's only 2 pages we're scraping so the extra work really isn't necessary\n",
    "    def start_requests(self):\n",
    "    \n",
    "        urls = [\n",
    "            \n",
    "        'http://www.http://quotes.toscrape.com/page/1/',\n",
    "        'http://www.http://quotes.toscrape.com/page/2/'\n",
    "        \n",
    "        ]\n",
    "    \n",
    "    #Now must have a loop to actually go and do the scraping \n",
    "    \n",
    "        for url in urls:\n",
    "        \n",
    "        #Need to call the scrapy.Request function and pass in url as a url parameter and will have define a callback function\n",
    "        \n",
    "            yield scrapy.Request(url = url, callback = self.parse)\n",
    "        \n",
    "    #Now need to define a callback function to have the above loop work\n",
    "    \n",
    "    def parse (self,response):\n",
    "        \n",
    "        #Will go back page number, to do that have to have the function check for the page number in the above urls\n",
    "        #Will take the last 2 characters and split the url where \"/\" occurs and use the page number as a function end parameter\n",
    "        \n",
    "        page = response.url.split(\"/\")[-2]\n",
    "        \n",
    "        #Will have a filename to match the above\n",
    "        filename = 'quotes-%s.html' % page\n",
    "        \n",
    "        #Will now write the scraped contents to a html file using the code below\n",
    "        with open(filename,'wb') as f:\n",
    "            f.write(response.body)\n",
    "            \n",
    "        #Although not necessary, will have a self log to see how it's doing as a means of troubleshooting\n",
    "        self.log('Saved File %s' % filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-21-3b7811a7cbdf>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-21-3b7811a7cbdf>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    scrapy crawl('quotes')\u001b[0m\n\u001b[1;37m               ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "scrapy crawl('quotes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
